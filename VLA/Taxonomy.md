[TOC]



# Aï¼š**Control & Reasoning Paradigmï¼ˆæ§åˆ¶èŒƒå¼ï¼‰**

> **è°åœ¨â€œæƒ³â€ï¼Œè°åœ¨â€œåšâ€ï¼Ÿ**

## A1. Policy-Centric VLAï¼ˆç«¯åˆ°ç«¯ï¼‰

* RT-1 / RT-2
* BC-Z
* PerAct
* OpenVLA

ğŸ“Œ ç‰¹ç‚¹ï¼š
ç«¯åˆ°ç«¯ imitation / RLï¼Œå¼±ç»„åˆæ³›åŒ–

## A2. Plannerâ€“Executor VLAï¼ˆä»»åŠ¡åˆ†è§£ï¼‰

* SayCan
* Code-as-Policies
* ProgPrompt
* Inner Monologue

ğŸ“Œ ç‰¹ç‚¹ï¼š
LLM è´Ÿè´£ high-level reasoningï¼Œä½å±‚ policy æ‰§è¡Œ

## A3. Agentic VLAï¼ˆé•¿æœŸäº¤äº’ï¼‰

* Voyager
* Eureka
* AutoGPT-style embodied agents

ğŸ“Œ æ ¸å¿ƒåŒºåˆ†ç‚¹ï¼š
**åœ¨çº¿ skill discovery / memory / curriculum**

> Voyager â‰  SayCan çš„å…³é”®åœ¨äºã€Œèƒ½å¦è‡ªæˆ‘è¿›åŒ–ã€

---

# Bï¼š**World Modeling Assumptionï¼ˆä¸–ç•Œå»ºæ¨¡ï¼‰**

> **æ¨¡å‹æ˜¯å¦æ˜¾å¼å­¦ä¹ ç¯å¢ƒåŠ¨åŠ›å­¦ï¼Ÿ**

## B1. No World Modelï¼ˆReactiveï¼‰

* RT-1
* BC-Z
* SayCanï¼ˆæœ¬è´¨ï¼‰

---

## B2. Explicit World Modelï¼ˆæ˜¾å¼åŠ¨åŠ›å­¦ï¼‰

* PlaNet
* Dreamer / DreamerV3
* TD-MPC / TD-MPC2
* MuZeroï¼ˆVLA æ‰©å±•ï¼‰

ğŸ“Œ å¼º planning / imaginationï¼Œä½†éš¾ scale åˆ°å¤æ‚è§†è§‰

---

## B3. Implicit World Modelï¼ˆéšå¼ï¼‰

* **Ï€0 / Ï€0.5**
* Gato
* Decision Transformer
* VIMA
* RT-2ï¼ˆéƒ¨åˆ†ï¼‰

ğŸ“Œ **Transformer æœ¬èº«å³ä¸–ç•Œæ¨¡å‹**ï¼ˆsequence = trajectoryï¼‰

---

# Cï¼š**Representation Formï¼ˆè¡¨ç¤ºèŒƒå¼ï¼‰**

> **Action / State / Language å¦‚ä½•è¿›å…¥æ¨¡å‹ï¼Ÿ**

## C1. Symbolic / Programmatic

* SayCan
* Code-as-Policies
* Behavior Trees + LLM

---

## C2. Latent Continuous

**è¿™æ˜¯å½“å‰å·¥ä¸šå’Œå­¦æœ¯çš„ä¸»æµ**

* PerActï¼ˆlatent voxel actionï¼‰
* CLIPort
* R3M-based policies
* VLM + latent policy heads

ğŸ“Œ ç‰¹ç‚¹ï¼š

* é token
* Action æ˜¯å‘é‡ / pose / heatmap
* æ³›åŒ–ä¾èµ– representation learningï¼Œè€Œéåºåˆ—å»ºæ¨¡

---

## C3. Tokenized Generalist Representation

> **Vision / Language / Action / State â†’ tokens**

* **Ï€0 / Ï€0.5**
* **Gato**
* Decision Transformer
* VIMAï¼ˆtoken actionï¼‰
* (æœªæ¥) Qwen-Embodied / Gemini Robotics

ğŸ“Œ è¿™æ˜¯ä½  V4 çš„æ­£ç¡®æŠ½è±¡ï¼Œä½†å®ƒæ˜¯ **è¡¨ç¤ºèŒƒå¼ï¼Œä¸æ˜¯å•ç‹¬ä¸€ä»£**

