**content**
<!-- TOC -->

- [RLHF](#rlhf)

<!-- /TOC -->


# RLHF

- https://github.com/OpenLLMAI/OpenRLHF

- [MIT哈佛等32人研究天团揭露RLHF最大弱点，囊括250+论文成果，挑战大模型机制](https://mp.weixin.qq.com/s/BCdX6PuEdSR7D3WJ4ffonA)
- [RLHF几大常用框架实践对比（trlx、deepspeedchat、colossalaichat）](https://zhuanlan.zhihu.com/p/626046758?utm_campaign=shareopn&utm_medium=social&utm_oi=615941546193850368&utm_psn=1646992448919416832&utm_source=wechat_session)

- https://github.com/GanjinZero/RRHF

- https://github.com/CarperAI/trlx

- https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat

- https://github.com/hpcaitech/ColossalAI/tree/main/applications/Chat

- https://github.com/OpenLMLab/MOSS-RLHF

- https://github.com/SupritYoung/Zhongjing
  - 医疗领域，使用了rlhf

- https://huggingface.co/blog/trl-peft