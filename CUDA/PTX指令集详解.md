[TOC]

> 本文主要基于cuda官方文档：[URL](https://docs.nvidia.com/cuda/parallel-thread-execution/#instruction-set)

## 指令集基础

### 基本指令格式

PTX 指令通常包含 0 到 4 个操作数，此外，在操作码左侧可通过 `@` 符号添加一个可选的谓词，具体形式如下：
- `@p   opcode;`
- `@p   opcode a;`
- `@p   opcode d, a;`
- `@p   opcode d, a, b;`
- `@p   opcode d, a, b, c;`


对于会生成结果值的指令：
- `d` 表示目标操作数
- `a`、`b`、`c` 表示源操作数


**特殊情况：**
1. 下面指令会写入两个目标寄存器，用 `|` 符号分隔多个目标寄存器。  
   示例：`setp.lt.s32  p|q, a, b;  // p = (a < b); q = !(a < b);`

2. 部分指令的目标操作数是可选的，可用下划线（`_`）表示的“bit bucket”操作数替代目标寄存器。

## MMA

- MMA（Matrix Multiply Accumulate）是 NVIDIA GPU 中用于高效矩阵乘法的指令集，在 Ampere 架构及后续版本中得到广泛应用。

- 矩阵乘法和累加操作的形式为`D = A * B + C`，其中`D`和`C`被称为累加器，可能引用相同的矩阵。

- MMA描述每个线程束执行矩阵乘法时处理的子矩阵尺寸。有两种操作可以执行warp级别的MMA操作：`wmma`和`mma`。在Hopper上，为了获得最高的性能，应该使用`wgmma`指令。

### 相关PTX代码

#### 半精度MMA指令

```shell
# 指令格式：mma.sync.aligned.<m>x<n>x<k>.<a布局>.<b布局>.<d数据类型>.<a数据类型>.<b数据类型>.<c数据类型> d, a, b, c;

# m8n8k4定义矩阵乘法的基础计算单元大小（与输出矩阵相关）
# m=8：输出矩阵 D 的行维度大小为 8
# n=8：输出矩阵 D 的列维度大小为 8
# k=4：收缩维度大小为 4，即 A 的列数和 B 的行数
# alayout 和 blayout 是占位符
mma.sync.aligned.m8n8k4.alayout.blayout.dtype.f16.f16.ctype  d, a, b, c;

# 计算 16×8 的输出矩阵
# 明确指定A为行优先，B为列优先
mma.sync.aligned.m16n8k8.row.col.dtype.f16.f16.ctype  d, a, b, c;

# 计算 16×8 的输出矩阵，K 维度进一步扩展到 16
mma.sync.aligned.m16n8k16.row.col.dtype.f16.f16.ctype d, a, b, c;

.alayout = {.row, .col};  # 指定矩阵 A 的存储布局：行优先
.blayout = {.row, .col};  # 指定矩阵 B 的存储布局：行优先
.ctype   = {.f16, .f32};  # 指定操作数C的数据类型，包含两种
.dtype   = {.f16, .f32};  # 指定操作数D数据类型，包含两种
```

#### 指令骨架

```shell
mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32
  {%Rd0, %Rd1, %Rd2, %Rd3},  # 输出矩阵D (4个FP32寄存器)
  {%Ra0, %Ra1, %Ra2, %Ra3},  # 输入矩阵A (4个FP16寄存器)
  {%Rb0, %Rb1},              # 输入矩阵B (2个FP16寄存器)
  {%Rc0, %Rc1, %Rc2, %Rc3};  # 累加矩阵C (4个FP32寄存器)
```

#### 该指令累加器矩阵的布局

![image](../assets/mma_layout.png)

这张图展示了 **MMA（矩阵乘法累加）指令中累加器矩阵 C/D 的分片布局**，对应 `mma.m16n8k16` 这类指令的硬件实现细节。核心是解释 **线程束（warp）内的线程如何协作处理 16×8 尺寸的累加器矩阵**，以下分层次拆解：

##### 基础概念

| 符号/维度  | 含义                             | 硬件关联                     |
| ---------- | -------------------------------- | ---------------------------- |
| `m16n8k16` | 输出矩阵尺寸：16行（M）×8列（N） | 每个线程束处理 16×8 的子矩阵 |
| `Row\Col`  | 矩阵的行（Row）和列（Col）索引   | 对应计算结果的二维位置       |
| `T0-T31`   | 线程束内的线程 ID（0-31）        | 32线程协作完成矩阵计算       |
| `{c0,c1}`  | 寄存器分片（Fragment）           | 线程存储的部分计算结果       |


##### 矩阵分片的「行-列-线程」映射
**1. 矩阵尺寸与线程分工**

- **目标矩阵**：16行（Row 0-15）×8列（Col 0-7），共 16×8=128 个元素。
- **线程束**：32个线程（T0-T31）协作，每个线程需处理 **128/32=4 个元素**（通过寄存器分片实现）。

**2. 行分组：2组×8行**

- 矩阵被分为 **2个行块**：
  - 第1块：Row 0-7（8行）
  - 第2块：Row 8-15（8行）

**3. 列分组：4列×2元素**

- 每列（Col 0-7）被拆分为 **2个元素的分片**（如 `{c0,c1}`、`{c2,c3}`）：
- 每个线程处理 **2个列元素**（通过寄存器存2个值），配合行处理实现 **4个元素/线程**（8行分组 × 2列分片 → 4元素/线程）。

**4\. 线程处理**

每个线程处理4个元素`c0`, `c1`, `c2`, `c3`。`c1`和`c2`之间的距离是8 * 8个元素。`c0`和`c1`一起是`8 bytes = 2 * sizeof(float)`


##### 硬件执行流程
1. **数据读取**：  
   线程束从全局内存/共享内存读取矩阵 A（16×16）、矩阵 B（16×8）的分片。  
   - A 矩阵：行优先存储，每个线程读取 2 个 FP16 元素（对应 `{a0,a1}` 分片）。  
   - B 矩阵：列优先存储，每个线程读取 2 个 FP16 元素（对应 `{b0,b1}` 分片）。  

2. **矩阵乘法**：  
   每个线程执行 **小矩阵乘法**（如 2×2×2），结果暂存到寄存器分片（如 `{c0,c1}`）。  

3. **累加同步**：  
   线程束内通过 `mma.sync` 指令同步，将 32 个线程的寄存器分片 **拼接成完整的 16×8 累加矩阵**，完成 `D += A×B + C` 的计算。    


##### 与 PTX 指令的映射
结合你之前的指令 `mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32` 看：
- `.row.col`：A 行优先、B 列优先，对应图中矩阵 A/B 的存储方式。  
- `.f32.f16.f16.f32`：累加器 C/D 用 FP32（分片 `{c0,c1}` 实际是 FP32 存储），A/B 用 FP16（线程读取的分片是 FP16）。  











