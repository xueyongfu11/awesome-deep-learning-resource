

- [大模型推理妙招—投机采样（Speculative Decoding）](https://zhuanlan.zhihu.com/p/651359908)

- [大模型推理优化实践：KV cache复用与投机采样](https://zhuanlan.zhihu.com/p/697801604)
  - 基于阿里RTP-LLM推理引擎的应用实践
  - 流量达到同一个实例
  - 使用投机采样技术