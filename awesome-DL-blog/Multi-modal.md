<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [汇总](#%E6%B1%87%E6%80%BB)
- [cross-modal retrieval](#cross-modal-retrieval)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->



## 汇总
- [POI名称生成竞赛二等奖方案分享](https://mp.weixin.qq.com/s/b3cvQkGho8e98eXj02zs8w)
  - NLP,CV,ML等
- [中科院自动化所最新《视觉-语言预训练》综述](https://mp.weixin.qq.com/s/niESB3_5_0o2MPy6SvEZyA)


## cross-modal retrieval
### 2022
- [Transformer Vision（二）|| ViT-B/16 网络结构](https://blog.csdn.net/qq_56039091/article/details/124785401)

### 2021
- [论文笔记-UNITER: Learning Universal Image-Text Representations](https://www.jianshu.com/p/457e668715e4)
- [ICML2021 | ALIGN：大力出奇迹，谷歌用18亿的图像-文本对训练了一个这样的模型](https://blog.csdn.net/moxibingdao/article/details/120320356)
- [用不匹配的图文对也能进行多模态预训练？百度提出统一模态的预训练框架：UNIMO（ACL2021）](https://blog.csdn.net/moxibingdao/article/details/122532003)
- [跨模态检索 | 图文检索梳理](https://zhuanlan.zhihu.com/p/392385222)
- [Wukong：一亿规模的中文跨模态预训练基准](https://zhuanlan.zhihu.com/p/551622338)
  - 华为开源的中文多模态数据集